# 具身抓取研究综述
https://mp.weixin.qq.com/s/e18Zxy-iZbeXe76cPBFMcQ
Original 陈萍萍的公主 一点人工一点智能

 _2025年04月03日 12:03_ _湖北_

编辑：陈萍萍的公主@一点人工一点智能

**入群邀请****：****8个专业方向交流群**

![](http://mmbiz.qpic.cn/mmbiz_png/tL6kLzIKAkoYGdIicPUicyTs8lAXywQpYXlZrH1ZEQasw1rb7PLKzQxqicgVJXHnOTiauIkeos5EH7ArnTf41Xj80g/300?wx_fmt=png&wxfrom=19)

**一点人工一点智能**

小工具集散地，知识随笔的分享小站

761篇原创内容

公众号

![Image](https://mmbiz.qpic.cn/mmbiz_png/tL6kLzIKAkric5r8IG4alRRwkA10IJlMichgpJytBxbhUTicBicqWA8NKoVdK5SY34ojso93ztdKicCXjfazXfpqY7Q/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1)

论文链接：https://www.mdpi.com/1424-8220/25/3/852

![Image](https://mmbiz.qpic.cn/mmbiz_png/tL6kLzIKAkop2a0xaoGzcY2vRj693NnWrwwNo8AG9QEBVzoTIHYh5iaOHia3VNeLbfDopTrHEUIQX0zTaicyJYKfQ/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1)

引言

具身抓取是机器人执行物理交互任务的核心基础。随着预训练模型在感知、推理和交互领域的突破，其在机器人抓取任务中的应用显著推动了该领域的发展。本文从具身基础、具身感知、具身策略和具身Agent四个维度系统梳理了最新进展。引言部分强调了预训练模型如何通过大规模数据学习先验知识，帮助机器人理解环境意图并提升动态环境下的自适应能力。例如，视觉基础模型（VFMs）通过点云提取和3D重建增强环境理解，而大语言模型（LLMs）则优化了自然语言指令的解析能力。

![Image](https://mmbiz.qpic.cn/mmbiz_png/tL6kLzIKAkric5r8IG4alRRwkA10IJlMicFjP07Zb8L28KApxWdIczYVrp7ZsltOlbgFSYicjt8YYxcrXBCCVGXJg/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1)

作者指出，传统机器人研究在视觉操控、强化学习和模仿学习等方面受限于数据稀缺与泛化能力不足。预训练模型通过特征提取、数据增强和奖励函数生成等机制，为解决这些问题提供了新思路。例如，在模仿学习中，预训练模型可作为特征编码器，提升模型对新场景的适应性；在强化学习中，通过语言模型生成任务相关的奖励函数，减少人工设计的依赖。这些技术突破为机器人抓取的智能化奠定了基础。

![Image](https://mmbiz.qpic.cn/mmbiz_png/tL6kLzIKAkop2a0xaoGzcY2vRj693NnWzv92oyuLvf2Bs8cpxFSuuDaTX1wy4HdF3H5CG8Az5dwpyzkEZ01oJQ/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1)

具身基础

![Image](https://mmbiz.qpic.cn/mmbiz_png/tL6kLzIKAkric5r8IG4alRRwkA10IJlMicthHXHPWucNFWuv3M7ViamOhTNdK4YMdgWK9x8DyuYX4zRFicYlIdl6vg/640?wx_fmt=png&from=appmsg&tp=wxpic&wxfrom=5&wx_lazy=1)

具身基础部分系统总结了机器人硬件平台、仿真环境、数据集和采集方法。硬件平台涵盖机械臂、末端执行器（如两指夹爪和灵巧手）、移动复合机器人（如轮式机械臂组合）和人形机器人。以Franka、xArm系列为代表的机械臂在工业与农业场景广泛应用，而仿真平台如Gazebo、PyBullet和Isaac Sim则降低了算法验证成本。值得注意的是，仿真与真实环境的差异（Sim2Real Gap）仍是主要挑战，例如摩擦力和碰撞动力学的建模不足。

公开数据集（如BridgeData V2、GraspNet-1Billion）和采集方法（如远程操作与动作捕捉）为算法训练提供了丰富资源。数据采集的低成本化趋势显著，例如ALOHA系统通过远程控制在模拟环境中生成数据，降低了人工标注成本。然而，现有数据集在物体多样性（如透明或柔性物体）和复杂场景覆盖上仍有局限，制约了模型的泛化能力。

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

预训练模型

预训练模型章节详细梳理了五类模型的发展脉络：

1）大语言模型（LLMs）：从BERT、GPT到GPT-4，模型通过自监督学习积累通用语义知识。GPT-4通过链式思维（Chain-of-Thought）实现了复杂推理，显著提升了任务分解和代码生成能力。例如，Eureka框架利用GPT-4生成可执行的奖励函数代码，优化强化学习策略。

2）视觉基础模型（VFMs）：DINOv2和MAE通过掩码自编码器学习鲁棒视觉特征，SAM模型支持开放词汇分割。这些模型在点云处理和3D重建中发挥关键作用，例如SAM2通过视频数据训练提升了分割精度和速度。

3）视觉语言模型（VLMs）：CLIP通过对比学习对齐图像与文本特征，BLIP-2引入课程学习策略增强多模态理解。CLIPORT模型融合语义流与空间流，实现了语言引导的抓取策略生成。

4）生成大模型（GLMs）：扩散模型（如Stable Diffusion）和DALL-E系列通过可控生成支持数据增强。例如，GenAug利用扩散模型生成多样化的模拟场景数据，缓解真实数据不足问题。

5）机器人领域专用模型（RDSMs）：MVP和R3M通过领域数据微调提升任务适应性。GR-1模型将语言指令与视觉观察结合，直接预测机器人动作，实现了端到端控制。

这些模型通过先验知识注入，显著提升了机器人对多模态输入（如视觉、语言）的理解能力。

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

具身感知

具身感知聚焦于机器人通过视觉传感器理解环境并预测抓取姿态。早期研究局限于2D姿态检测（3自由度），而当前主流方法转向6自由度抓取，结合深度信息与点云处理提升精度。例如，VL-Grasp通过两阶段框架：首先利用BERT和ResNet定位目标，再通过点云滤波和姿态检测网络预测最优抓取位姿。

三维特征融合是核心研究方向：

1）语义与几何特征融合：Polarnet和GraspGPT将语言描述与点云特征结合，通过兼容性评估筛选候选抓取位姿。PhyGrasp利用Llama 2编码语言特征，生成抓取热图。

2）点云提取：OVGNet通过GroundingDINO融合图像与文本特征，分割目标点云。

3）功能信息提取：OpenAD通过零样本泛化技术，将功能标签映射到新物体。Ram模型构建功能记忆库，支持跨场景迁移。

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

三维场景重建通过神经辐射场（NeRF）或3D高斯表示增强几何理解。例如，LERF-TOGO结合CLIP和DINO特征，实现零样本任务导向抓取；GaussianGrasper利用SAM分割先验加速重建。扩散模型（如GNFactor）通过2D语义特征生成3D神经场，提升场景交互理解。

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

具身策略

具身策略分为模仿学习（Imitation Learning）和强化学习（Reinforcement Learning）两类，均依赖预训练模型提升性能。

5.1 模仿学习

模仿学习通过专家轨迹数据训练策略网络，其核心框架是行为克隆（Behavior Cloning, BC）。损失函数定义为：

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

其中，策略πθ通过最大化专家动作的对数似然进行优化。为提升数据效率，预训练模型的应用分为两类：

· 数据增强：GreenAug利用图像生成模型修改交互对象与背景；GenSim通过代码生成模拟专家演示。

· 特征提取：DROID使用DistilBERT编码语言指令，CLIPORT融合视觉与语义特征生成抓取策略。

扩散策略（Diffusion Policy）创新性地引入去噪扩散模型，从噪声中生成平滑动作序列。该方法通过梯度场优化动作，提升策略稳定性。

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

5.2 强化学习

强化学习通过马尔可夫决策过程（MDP）建模，目标为最大化累积奖励：

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

传统方法依赖人工设计奖励函数，而预训练模型通过两种方式优化：

· 奖励函数生成：Text2Reward利用LLMs生成Python代码形式的奖励函数；Eureka通过进化搜索迭代优化奖励设计。

· 奖励信号估计：VoxPoser通过视觉语言模型生成3D价值地图，引导运动规划；Diffusion Reward利用专家视频训练生成模型，以条件熵作为奖励信号。

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

具身Agent

具身Agent分为分层执行（Hierarchical Execution）和整体执行（Holistic Execution）两类架构。

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

1）分层执行

· 低层控制策略：传统控制（如MPC）与策略学习（如强化学习）结合。例如，LMPC利用PaLM 2分解任务，MPC计算关节运动轨迹。

· 技能库：SayCan通过LLMs分解高层指令，调用预定义技能（如“抓取物体”）；VoicePilot通过API函数库实现语音控制。

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

2）整体执行

· 端到端训练：RT-1和RT-2模型将机器人状态与视觉输入直接映射为动作，支持多任务泛化。

· 视频预测：VLP通过文本生成视频计划，逆运动学模型解析动作序列；Dreamitate利用扩散模型生成任务执行视频，指导机器人模仿。

· 视觉语言模型直接控制：ZSTG通过GPT-4生成密集末端姿态序列，无需预定义技能库。

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

挑战与展望

当前研究面临五大挑战：

· 数据集获取：仿真与真实环境差异、数据多样性与标准化不足。

· 模型适应性：动态环境噪声、任务分解的实时性与计算资源限制。

· 策略泛化性：对特殊材料或形状物体的抓取能力有限，物理常识推理不足。

· 长序列任务执行：任务连续性建模与实时重规划能力待提升。

· 可解释性：复杂模型的决策过程缺乏透明度，多模态特征贡献难以量化。

未来方向包括：

· 开发高保真、低耗能的仿真平台；

· 设计轻量化模型架构与跨模态整合方法；

· 增强物理属性感知与常识推理能力；

· 探索任务分解的自主学习机制。

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

结论

本文系统综述了预训练模型在具身抓取中的应用，从基础平台到高层策略均展现了显著进展。预训练模型通过先验知识注入，解决了数据稀缺与泛化难题，推动了机器人抓取的智能化。然而，真实场景的复杂性仍对模型的适应性、泛化性和可解释性提出严峻挑战。未来需进一步探索多模态融合、物理常识建模与高效学习框架，以实现机器人在开放环境中的自主操作能力。

**—— 精彩推荐 ——**

1. [具身智能中 VLA 主流方案全解析：技术总结与未来展望](https://mp.weixin.qq.com/s?__biz=MzUyMDc5OTU5NA==&mid=2247704735&idx=3&sn=f0b7a65bcf795fdcd2dcbc0079d71bda&scene=21#wechat_redirect)

2. [基于大模型的具身智能系统综述](https://mp.weixin.qq.com/s?__biz=MzUyMDc5OTU5NA==&mid=2247703684&idx=1&sn=9961ef869181a225a51ea05265ee4f9d&scene=21#wechat_redirect)  

3. [CMU把具身智能的机器人给越狱了](https://mp.weixin.qq.com/s?__biz=MzUyMDc5OTU5NA==&mid=2247702404&idx=3&sn=44fcd18154fc220c4136f9dccd5af3b1&scene=21#wechat_redirect)

4. [清华团队破解具身智能Scaling Law，GPT时刻在即！宁德时代联创终于出手](https://mp.weixin.qq.com/s?__biz=MzUyMDc5OTU5NA==&mid=2247694432&idx=1&sn=8212720450182054b56f6988a8771938&scene=21#wechat_redirect)

5. [你真的知道什么是具身智能吗？一文带你了解！](https://mp.weixin.qq.com/s?__biz=MzUyMDc5OTU5NA==&mid=2247689734&idx=3&sn=574eee52750b5c58e664142e2c090e86&scene=21#wechat_redirect)

![Image](data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8'%3F%3E%3Csvg width='1px' height='1px' viewBox='0 0 1 1' version='1.1' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke='none' stroke-width='1' fill='none' fill-rule='evenodd' fill-opacity='0'%3E%3Cg transform='translate(-249.000000, -126.000000)' fill='%23FFFFFF'%3E%3Crect x='249' y='126' width='1' height='1'%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E)

点击“**阅读原文**”，解锁更多资料